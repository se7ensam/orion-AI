# Orion Architecture

## Overview

Orion is an intelligent document management system that leverages Large Language Models (LLMs), Neo4j graph database, and Oracle AI Vector DB to create a comprehensive knowledge graph from organizational documents.

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interface                            â”‚
â”‚                    (CLI / API / Web Interface)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                         â”‚
                â–¼                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Python       â”‚        â”‚  LangChain     â”‚
        â”‚  Backend      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”¤  Framework     â”‚
        â”‚  (CLI/API)    â”‚        â”‚  (Orchestrationâ”‚
        â”‚               â”‚        â”‚   & LLM Chain) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
    â”‚           â”‚           â”‚            â”‚
    â–¼           â–¼           â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Neo4j  â”‚ â”‚ Oracle  â”‚ â”‚ Ollama  â”‚ â”‚ Document â”‚
â”‚  Graph  â”‚ â”‚ AI      â”‚ â”‚ / LM    â”‚ â”‚ Parser   â”‚
â”‚  DB     â”‚ â”‚ Vector  â”‚ â”‚ Studio  â”‚ â”‚          â”‚
â”‚         â”‚ â”‚ DB      â”‚ â”‚         â”‚ â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Components

### 1. CLI Interface
- **Location**: `src/cli.py`
- **Purpose**: Unified command-line interface for all operations
- **Commands**:
  - `download` - Download SEC EDGAR filings
  - `setup-db` - Initialize database schema
  - `test-db` - Test database connections
  - `test` - Run test suite

### 2. Database Layer

#### Neo4j Graph Database
- **Location**: `src/database/neo4j_connection.py`
- **Purpose**: Store document relationships and metadata
- **Schema**: See [neo4j_schema.md](neo4j_schema.md)
- **Node Types**: Employee, Document, Project, Department, Author
- **Relationships**: WORKED_ON, BELONGS_TO, WROTE, PART_OF, MEMBER_OF

#### Oracle AI Vector DB
- **Location**: `src/database/oracle_connection.py`
- **Purpose**: Store document embeddings for semantic search
- **Status**: Basic connection implemented, vector operations TODO

### 3. Ingestion Layer

#### SEC EDGAR Ingestion
- **Location**: `src/ingestion/`
- **Components**:
  - `sec_companies.py` - Company index parser
  - `filing_downloader.py` - Filing downloader and exhibit extractor
  - `main.py` - Entry point
- **Features**:
  - Downloads 6-K filings for Foreign Private Issuers
  - Extracts EX-99 exhibits
  - Respects SEC rate limits
  - Resume capability

### 4. LLM Integration (TODO)
- **Location**: `src/services/llm_service.py` (to be created)
- **Purpose**: Document processing and semantic understanding
- **Integration**: LangChain with Ollama/LM Studio
- **Features** (planned):
  - Text extraction and summarization
  - Entity recognition
  - Relationship extraction

### 5. Document Processing (TODO)
- **Location**: `src/services/document_service.py` (to be created)
- **Purpose**: Process and analyze documents
- **Features** (planned):
  - Document parsing
  - Embedding generation
  - Graph node creation

## Data Flow

### Document Ingestion Flow
```
1. SEC EDGAR Download
   â””â”€> filing_downloader.py
       â””â”€> Downloads 6-K filings
       â””â”€> Extracts EX-99 exhibits
       â””â”€> Saves to Edgar_filings/

2. Document Processing (TODO)
   â””â”€> document_service.py
       â””â”€> Parse documents
       â””â”€> Extract entities
       â””â”€> Generate embeddings

3. LLM Analysis (TODO)
   â””â”€> llm_service.py
       â””â”€> Summarize documents
       â””â”€> Extract relationships
       â””â”€> Identify entities

4. Graph Creation (TODO)
   â””â”€> Create nodes in Neo4j
   â””â”€> Create relationships
   â””â”€> Store metadata

5. Vector Storage (TODO)
   â””â”€> Store embeddings in Oracle
   â””â”€> Enable semantic search
```

## Technology Stack

### Core Technologies
- **Python**: 3.9+ (managed via Conda)
- **Conda**: Environment and dependency management
- **Neo4j**: Graph database
- **Oracle AI Vector DB**: Vector storage
- **LangChain**: LLM orchestration framework

### Python Packages
- **neo4j**: Neo4j driver
- **oracledb**: Oracle database driver
- **langchain**: LLM framework
- **langchain-ollama**: Ollama integration
- **requests**: HTTP client
- **beautifulsoup4**: HTML parsing
- **tqdm**: Progress bars

## Project Structure

```
orion/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli.py                    # Main CLI interface
â”‚   â”œâ”€â”€ database/                 # Database connections
â”‚   â”‚   â”œâ”€â”€ neo4j_connection.py
â”‚   â”‚   â””â”€â”€ oracle_connection.py
â”‚   â”œâ”€â”€ ingestion/               # SEC EDGAR ingestion
â”‚   â”‚   â”œâ”€â”€ sec_companies.py
â”‚   â”‚   â”œâ”€â”€ filing_downloader.py
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ services/                # Business logic (TODO)
â”‚   â”‚   â”œâ”€â”€ document_service.py
â”‚   â”‚   â””â”€â”€ llm_service.py
â”‚   â””â”€â”€ models/                  # Data models (TODO)
â”‚       â””â”€â”€ graph_models.py
â”œâ”€â”€ docs/                        # Documentation
â”œâ”€â”€ environment.yml              # Conda environment
â””â”€â”€ setup_conda.sh              # Setup script
```

## Development Status

### âœ… Completed
- Project structure
- Conda environment setup
- Neo4j connection and schema
- SEC EDGAR ingestion pipeline
- CLI interface
- Documentation

### ðŸš§ In Progress
- Oracle AI Vector DB integration
- Document processing service
- LLM integration

### ðŸ“‹ Planned
- Graph node creation from documents
- Relationship discovery
- Semantic search
- API endpoints
- Web interface

## Configuration

### Environment Variables
All configuration is managed through `.env` file:
- Database connections (Neo4j, Oracle)
- LLM endpoints (Ollama, LM Studio)
- Application settings

See main [README.md](../README.md) for configuration details.

## Dependencies

All dependencies are managed through Conda:
- Defined in `environment.yml`
- Installed via `conda env create -f environment.yml`
- No pip/venv installation supported

See [CONDA_SETUP.md](CONDA_SETUP.md) for details.

